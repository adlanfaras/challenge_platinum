{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af12ce1-d2e6-458f-91f8-424a86a2dd25",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05700517-9c11-4cc2-a4e3-161f37e35712",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798c750d-692a-40f4-9dc6-d0ed0ab84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613b6078-76be-4f5a-9a33-210901332dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "df = pd.read_csv(\"train_preprocess.tsv.txt\" ,encoding=\"latin1\",sep='\\t',header=None,names=[\"Text\",\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abcf5f3-6808-4a1c-b314-5d91280bbcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24b18ba-5a5c-42ba-a864-31b441a076d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8fdf1a-d482-4981-b2f4-84b90c41093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     0\n",
       "Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff46e36e-ec40-4c0c-9c23-b1b163dc0507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terdapat 0 duplicated data\n",
      "Duplicated data sudah dihapus\n"
     ]
    }
   ],
   "source": [
    "# Hapus Duplicate Data\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "print('Terdapat {} duplicated data'.format(df.duplicated().sum()))\n",
    "print('Duplicated data sudah dihapus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903cb98-c44a-4dab-b91d-d7e75a2cc1a0",
   "metadata": {},
   "source": [
    "## Text Processing / Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fa2a7e-a7ef-4042-9c36-b958e9521544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alay = pd.read_csv('new_kamusalay.csv', encoding='ISO-8859-1', header=None)\n",
    "df_alay = df_alay.rename(columns={0: 'alay', 1: 'formal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f060a18-c534-460b-bc02-4c2ef6404271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alay</th>\n",
       "      <th>formal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  alay                    formal\n",
       "0  anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1         pakcikdahtua         pak cik sudah tua\n",
       "2       pakcikmudalagi         pak cik muda lagi\n",
       "3          t3tapjokowi              tetap jokowi\n",
       "4                   3x                 tiga kali"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17731424-e491-4299-98ca-bcdb875f49c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "list_stopwords = set(stopwords.words('indonesian'))\n",
    "\n",
    "def data_cleaning (text):\n",
    "    text = re.sub ('\\\\n','', text)\n",
    "    text = re.sub ('RT',' ', text)\n",
    "    text = re.sub ('USER', ' ', text)\n",
    "    text = re.sub ('user', ' ', text)\n",
    "    text = re.sub ('(http|https):\\/\\/s+', ' ', text)\n",
    "    text = re.sub ('[^0-9a-zA-Z]+', ' ', text)\n",
    "    text = re.sub ('x[a-z0-9]{2}', ' ', text)\n",
    "    text = re.sub (\"\\d+\", ' ', text)\n",
    "    text = re.sub ('  +', '', text)\n",
    "    return text\n",
    "\n",
    "def case_folding (text):\n",
    "    return text.lower()\n",
    "\n",
    "def alay_normalization(text):\n",
    "    res = ''\n",
    "    for item in text.split():\n",
    "        if item in df_alay['alay'].values:\n",
    "            res += df_alay[df_alay['alay'] == item]['formal'].iloc[0]\n",
    "        else:\n",
    "            res += item\n",
    "        res += ' '\n",
    "    return res\n",
    "\n",
    "def stopword_removal(text):\n",
    "    resp = ''\n",
    "    for item in text.split():\n",
    "        if item not in list_stopwords:\n",
    "            resp += item\n",
    "        resp +=' '\n",
    "    clean = re.sub('  +', ' ', resp)\n",
    "    return clean\n",
    "\n",
    "def cleansing(text):\n",
    "    text = data_cleaning(text)\n",
    "    text = case_folding(text)\n",
    "    text = alay_normalization(text)\n",
    "    text = stopword_removal(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eba5e73-f25d-4831-a645-2107c2b05aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleansing\n",
    "df['Text_clean'] = df['Text'].apply(cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b6a6d9-0813-417e-95f6-a0387594d69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus kmmbri hujjah partai diwlh s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung nya nya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya unbo paket barang nya bagus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh mahasiswa sombong kasih kartu kuning bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "\n",
       "                                          Text_clean  \n",
       "0  warung dimiliki pengusaha pabrik puluhan terke...  \n",
       "1  mohon ulama lurus kmmbri hujjah partai diwlh s...  \n",
       "2  lokasi strategis jalan sumatra bandung nya nya...  \n",
       "3  betapa bahagia nya unbo paket barang nya bagus...  \n",
       "4  aduh mahasiswa sombong kasih kartu kuning bela...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48091b44-2c00-497c-8413-1374a1cff8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Membuat koneksi ke database SQLite\n",
    "conn = sqlite3.connect('database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9157baa6-f45d-4895-a1d5-4cdb25383ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10933"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menyimpan DataFrame ke dalam tabel 'tabel_cleansed' dalam database\n",
    "df.to_sql('tabel_cleansed', con=conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d4c9f42-226b-4bb0-92a3-87beb49aee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame yang telah di-cleansing berhasil disimpan ke dalam tabel 'tabel_cleansed' di database.\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame yang telah di-cleansing berhasil disimpan ke dalam tabel 'tabel_cleansed' di database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45a2ddc-7fda-44c6-a255-a667f6d9eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b34481ec-31ca-4d88-bba1-d35452f67e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus kmmbri hujjah partai diwlh s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung nya nya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya unbo paket barang nya bagus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh mahasiswa sombong kasih kartu kuning bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text     Label  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "\n",
       "                                          Text_clean  \n",
       "0  warung dimiliki pengusaha pabrik puluhan terke...  \n",
       "1  mohon ulama lurus kmmbri hujjah partai diwlh s...  \n",
       "2  lokasi strategis jalan sumatra bandung nya nya...  \n",
       "3  betapa bahagia nya unbo paket barang nya bagus...  \n",
       "4  aduh mahasiswa sombong kasih kartu kuning bela...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from database\n",
    "\n",
    "db = sqlite3.connect('database.db', check_same_thread = False)\n",
    "q_data = 'SELECT * FROM tabel_cleansed'\n",
    "data = pd.read_sql_query(q_data, db)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f85b6ac-6ea9-4f64-9097-4841e2921ee3",
   "metadata": {},
   "source": [
    "## Feature-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ba81b0-5da6-48b8-a79e-356251cda089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 6383, Neu: 1138, Neg: 3412\n",
      "Total data: 10933\n"
     ]
    }
   ],
   "source": [
    "neg = df.loc[df.Label == 'negative'].Text_clean.tolist()\n",
    "neu = df.loc[df.Label == 'neutral'].Text_clean.tolist()\n",
    "pos = df.loc[df.Label == 'positive'].Text_clean.tolist()\n",
    "\n",
    "neg_label = df.loc[df.Label == 'negative'].Label.tolist()\n",
    "neu_label = df.loc[df.Label == 'neutral'].Label.tolist()\n",
    "pos_label = df.loc[df.Label == 'positive'].Label.tolist()\n",
    "\n",
    "total_data = pos + neu + neg\n",
    "labels = pos_label + neu_label + neg_label\n",
    "\n",
    "print(\"Pos: %s, Neu: %s, Neg: %s\" % (len(pos), len(neu), len(neg)))\n",
    "print(\"Total data: %s\" % len(total_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6971b63f-52c6-40ef-aceb-681fcc0885c8",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c461484a-4878-47de-afaf-f50fcdcaacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ae6eb8e-a790-4308-bb02-48be29810c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pickle has created!\n",
      "x_pad_sequences.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and pad sequence\n",
    "\n",
    "max_features = 100000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', lower=True)\n",
    "tokenizer.fit_on_texts(total_data)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"tokenizer.pickle has created!\")\n",
    "\n",
    "X = tokenizer.texts_to_sequences(total_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "maxlen = max(len(x) for x in X)\n",
    "\n",
    "X = pad_sequences(X)\n",
    "with open('x_pad_sequences.pickle', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"x_pad_sequences.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83fb5fd9-9edd-4ef7-a7f2-330990ac2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction for labels\n",
    "\n",
    "Y = pd.get_dummies(labels)\n",
    "Y = Y.values\n",
    "\n",
    "with open('y_labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"y_labels.pickle has created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded70fb-86b9-459b-8a74-816a477c5769",
   "metadata": {},
   "source": [
    "# Split traning and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1236880a-8ec5-4e18-9f8a-1e5cb97a537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c4bb265-06ab-4828-a94c-b60b890af78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test data with proportion 80:20\n",
    "\n",
    "file = open(\"x_pad_sequences.pickle\",'rb')\n",
    "X = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"y_labels.pickle\",'rb')\n",
    "Y = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74052454-56a0-4c7c-a723-e73dc80d5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply oversampling using SMOTE\n",
    "sm = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2ce35-fb6b-4759-ab8c-7a5992ea7c2b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd6dd667-54ff-4914-8c69-0efb465a4f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 58, 256)           25600000  \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 58, 256)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                36992     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25637091 (97.80 MB)\n",
      "Trainable params: 25637091 (97.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "60/60 [==============================] - 101s 1s/step - loss: 0.9716 - accuracy: 0.5252 - val_loss: 0.8146 - val_accuracy: 0.5812\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 66s 1s/step - loss: 0.7931 - accuracy: 0.6288 - val_loss: 0.6789 - val_accuracy: 0.7156\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.7319 - accuracy: 0.6745 - val_loss: 0.6712 - val_accuracy: 0.7193\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.6701 - accuracy: 0.7104 - val_loss: 0.5897 - val_accuracy: 0.7787\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 62s 1s/step - loss: 0.6053 - accuracy: 0.7507 - val_loss: 0.5484 - val_accuracy: 0.8002\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 69s 1s/step - loss: 0.5577 - accuracy: 0.7754 - val_loss: 0.5016 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.5134 - accuracy: 0.7940 - val_loss: 0.4921 - val_accuracy: 0.8226\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 74s 1s/step - loss: 0.4750 - accuracy: 0.8142 - val_loss: 0.4855 - val_accuracy: 0.8258\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 70s 1s/step - loss: 0.4445 - accuracy: 0.8282 - val_loss: 0.4592 - val_accuracy: 0.8372\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 72s 1s/step - loss: 0.4214 - accuracy: 0.8393 - val_loss: 0.4823 - val_accuracy: 0.8285\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim, input_length= X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.76))\n",
    "model.add(LSTM(32, dropout=0.77, recurrent_dropout=0.76))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=256, validation_data=(X_test, y_test), verbose=1, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e07cf2c-490f-4578-bf36-5c14dc7ac5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 4s 19ms/step\n",
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       681\n",
      "           1       0.68      0.82      0.74       235\n",
      "           2       0.95      0.81      0.87      1271\n",
      "\n",
      "    accuracy                           0.83      2187\n",
      "   macro avg       0.78      0.83      0.80      2187\n",
      "weighted avg       0.85      0.83      0.83      2187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "y_pred = predictions\n",
    "matrix_test = metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Testing selesai\")\n",
    "print(matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c31775-a659-488c-853f-9d45ebbf3827",
   "metadata": {},
   "source": [
    "### Selanjutnya akan dilakukan training model menggunakan algoritma LSTM, serta melakukan cross validation untuk memeriksa kestabilan kinerja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ae03a-f8b2-4216-8e49-d348f359d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "y = Y\n",
    "\n",
    "embed_dim = 256\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X), start=1):\n",
    "\n",
    "    data_train   = X[data[0]]\n",
    "    target_train = y[data[0]]\n",
    "\n",
    "    data_test    = X[data[1]]\n",
    "    target_test  = y[data[1]]\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim, input_length= X.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.76))\n",
    "    model.add(LSTM(32, dropout=0.77, recurrent_dropout=0.76))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0)\n",
    "    history = model.fit(X_train_resampled, y_train_resampled, epochs=10, batch_size=256, validation_data=(X_test, y_test), verbose=0, callbacks=None)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    y_pred = predictions\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print(\"Rata-rata Accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ed926-c63b-4747-94aa-a7f554ddc8ed",
   "metadata": {},
   "source": [
    "## Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101d244-89be-49b4-8a9e-d8e6fc774330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70e022-c672-4bb7-bc26-5e7f1b1abc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_lstm.h5')\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00541235-f37e-461a-9b9c-075492871cc4",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27f540-2058-4b61-9230-d733c296ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4df23-a675-4c27-a188-25a4cd2aa39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Makanannya dan minumannya enak  \"\"\"\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('model_lstm.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: %s\" % text[0])\n",
    "print(\"Sentiment: %s\" % sentiment[polarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fada72-7d3d-43f5-98df-7d8ca86f9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "sekolah di bogor tidak ada yang bagus  \"\"\"\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('model_lstm.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: %s\" % text[0])\n",
    "print(\"Sentiment: %s\" % sentiment[polarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b162e-9ee1-4651-83c2-40c55f6676b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"saya tidur\"\"\"\n",
    "\n",
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model('model_lstm.h5')\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "hasil = sentiment[polarity]\n",
    "\n",
    "print(\"Text: %s\" % text[0])\n",
    "print(\"Sentiment: %s\" % sentiment[polarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fa932-0f5f-459b-8499-860f178d7ebb",
   "metadata": {},
   "source": [
    "# **Prediksi Data Tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d20bc-9164-458f-89d0-24a83b9952e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_twt = 'Data Tweet/data.csv'\n",
    "df_tweet = pd.read_csv(data_twt, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5488f-b662-45ce-99dd-087f43033f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_tweet[['Tweet']].copy()\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d853f4-84b3-4cc8-9678-4ccf1b0666c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = ['negative', 'neutral', 'positive']\n",
    "\n",
    "def get_sent(sent):\n",
    "    if sent==0:\n",
    "        sent='negative'\n",
    "    elif sent==1:\n",
    "        sent='neutral'\n",
    "    else: sent='positive'\n",
    "    return sent\n",
    "\n",
    "file_tokenizer = open('tokenizer.pickle', 'rb')\n",
    "file_sequencer = open('x_pad_sequences.pickle', 'rb')\n",
    "load_tokenizer = pickle.load(file_tokenizer)\n",
    "load_sequencer = pickle.load(file_sequencer)\n",
    "file_sequencer.close()\n",
    "model_lstm = load_model('model_lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dee045-3221-4170-a6d5-bfaadbe575e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = df_predict['Tweet']\n",
    "\n",
    "data_processed= []\n",
    "for text in data_pre:\n",
    "  text = cleansing(text)\n",
    "  data_processed.append(text)\n",
    "    \n",
    "feature = load_tokenizer.texts_to_sequences(data_processed)\n",
    "sequences= pad_sequences(feature, maxlen=load_sequencer.shape[1])\n",
    "\n",
    "prediction = model_lstm.predict(sequences)\n",
    "get_sentiment = np.argmax(prediction, axis=1)\n",
    "get_sentiment = get_sentiment.reshape(-1,1)\n",
    "\n",
    "get= []\n",
    "for text in get_sentiment:\n",
    "    sent= get_sent(text)\n",
    "    get.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9745f-dfe8-4254-afc1-170947d2955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict['Text_Clean']= data_processed\n",
    "df_predict['Sentiment']= get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfdd4e-34f4-4339-8b14-d1ca51938aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c8954-37ed-44e2-8a65-13a2e592d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_palette = sns.color_palette(\"Set2\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='Sentiment', data=df_predict, palette=color_palette)\n",
    "\n",
    "# Menambahkan label angka pada setiap bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# Menambahkan label sumbu dan judul\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Jumlah')\n",
    "plt.title('Countplot Sentiment')\n",
    "\n",
    "# Menampilkan plot\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
